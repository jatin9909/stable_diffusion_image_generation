import streamlit as st 
from typing import Optional, Literal
import requests
#from dotenv import load_dotenv
import os 
#import openai
from PIL import Image
from diffusers import StableDiffusionPipeline, StableDiffusionControlNetImg2ImgPipeline, StableDiffusionXLControlNetPipeline, ControlNetModel, AutoencoderKL, StableDiffusionImg2ImgPipeline, AutoencoderKL, ControlNetModel, StableDiffusionControlNetPipeline, UniPCMultistepScheduler
from diffusers.utils import load_image
import numpy as np
import cv2
from PIL import Image
import torch
from sd2.generate import PIPELINE_NAMES, generate
from io import BytesIO
from controlnet_aux import LineartDetector

device = "cuda"
url = "C:/Users/user1/Desktop/stable-diffusion-2-xl-streamlit/Data package from March 22nd/Image_015.jpg"

#function to generate AI based images using Huggingface Diffusers
def generate_images_using_huggingface_diffusers(text):
    pipe = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16)
    pipe = pipe.to("cuda")
    prompt = text
    image = pipe(prompt).images[0] 
    return image

#Streamlit Code
choice = st.sidebar.selectbox("Select your choice", ["Home", "Text To Image", "Selfie Image generation"])

if choice == "Home":
    st.title("AI Image Generation App")
    with st.expander("About the App"):
        st.write("This is a simple image generation app that uses AI to generates images from text prompt.")


elif choice == "Text To Image":
    st.subheader("Text to Image generation by Mythyaverse")
    input_prompt = st.text_input("Enter your text prompt")
    if input_prompt is not None:
        if st.button("Generate Image"):
            image_output = generate_images_using_huggingface_diffusers(input_prompt)
            st.info("Generating image.....")
            st.success("Image Generated Successfully")
            st.image(image_output, caption="Generated by Huggingface Diffusers")

elif choice == "Selfie Image generation":
    st.subheader("Selfie Image generation by Mythyaverse")

    #checkpoint = "ControlNet-1-1-preview/control_v11p_sd15_lineart"
    #processor = LineartDetector.from_pretrained("lllyasviel/Annotators")
    # Load the image-to-image model and scheduler
    model_id = "SG161222/Realistic_Vision_V2.0"
    #checkpoint_path = "models/Realistic_Vision_V2.0-fp16-no-ema.safetensors"
    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
    # Load the SafeTensor weights
    #pipe.model.load_state_dict(SafeTensors.load_file(checkpoint_path))
    #pipe = StableDiffusionPipeline.from_single_file(checkpoint_path)
    #vae = AutoencoderKL.from_pretrained("stabilityai/sd-vae-ft-mse", torch_dtype=torch.float16).to("cuda")
    #pipe.vae = vae                                                                                                                                                                                                     
    #pipe = pipe.to(device)
    
    col1, col2 = st.columns(2)

    with col1:
        init_image = st.file_uploader("Upload an initial image", type=["png", "jpg"])
        print(init_image)
        if init_image:
            init_image = Image.open(init_image)
            st.image(init_image)

    with col2:
        if init_image:
           input_prompt = st.text_input("Enter your text prompt")
           negative_prompt = st.text_input("Enter negative prompt")


           # Run image-to-image conversion
        if st.button("Generate Image"):
            if init_image is not None:
                
                init_image = Image.fromarray(np.uint8(np.asarray(init_image)))
                # Get the size of the uploaded image
                init_image = init_image.resize((1200, 1600))
                #control_image = processor(init_image)
                #controlnet = ControlNetModel.from_pretrained(checkpoint, torch_dtype=torch.float16)
                pipe = pipe.to(device)
                images = pipe(prompt=input_prompt, image=init_image, strength=0.75, guidance_scale=7.5).images
                st.image(images[0])